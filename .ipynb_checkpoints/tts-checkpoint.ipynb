{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c119c37a-40d6-4db0-88c1-3e89988a9537",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hparams'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhifi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtacotron2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhparams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_hparams\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hparams'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('hifi')\n",
    "sys.path.append('tacotron2')\n",
    "from hparams import create_hparams\n",
    "import torch\n",
    "import json\n",
    "from model import Tacotron2\n",
    "from audio_processing import griffin_lim\n",
    "from text import text_to_sequence\n",
    "from env import AttrDict\n",
    "from meldataset import mel_spectrogram, MAX_WAV_VALUE\n",
    "from models import Generator\n",
    "from scipy.io.wavfile import write\n",
    "#from denoiser import Denoiser\n",
    "checkpoint_path = \"tacotron2/humphery-300\"\n",
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050\n",
    "hparams.max_decoder_steps = 3000 # Max Duration\n",
    "hparams.gate_threshold = 0.25 # Model must be 25% sure the clip is over before ending generation\n",
    "model = Tacotron2(hparams)\n",
    "state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))['state_dict']\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()  # set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538c247f-4065-42b0-967a-84e1a8ccadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "parser.add_argument('-t', type=str, help='txt')\n",
    "parser.add_argument('-f', type=str, help='file')\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Access the arguments\n",
    "p1 = args.t\n",
    "p2 = args.f\n",
    "\n",
    "\n",
    "def generate_wav(text, output)\n",
    "    sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "    sequence = torch.autograd.Variable(\n",
    "        torch.from_numpy(sequence)).long()\n",
    "    \n",
    "    # Decode text input to get mel spectrogram\n",
    "    model.eval()\n",
    "    _, mel_outputs_postnet, _, _ = model.inference(sequence)\n",
    "    \n",
    "    # Load HiFi-GAN generator\n",
    "    hifi_gan_config = AttrDict(json.load(open(\"hifi/config_v1.json\")))\n",
    "    generator = Generator(hifi_gan_config)\n",
    "    state_dict_g = torch.load('hifimodel_config_v1', map_location=torch.device('cpu'))\n",
    "    generator.load_state_dict(state_dict_g['generator'])\n",
    "    generator.eval()\n",
    "    \n",
    "    # Convert mel spectrogram to waveform using HiFi-GAN\n",
    "    with torch.no_grad():\n",
    "        mel = mel_outputs_postnet.squeeze(0)\n",
    "        if len(mel.shape) == 2:\n",
    "            mel = mel.unsqueeze(0)\n",
    "        audio = generator(mel).squeeze()\n",
    "        audio = audio * MAX_WAV_VALUE\n",
    "        audio = audio.squeeze().numpy().astype('int16')\n",
    "    \n",
    "    # Save output waveform to .wav file\n",
    "    file_name = \"voice_output/\" + str(output) + \".wav\"\n",
    "    write(output, hparams.sampling_rate, audio)\n",
    "\n",
    "if p1:\n",
    "    output = 1\n",
    "    generate_wav(p1,output)\n",
    "\n",
    "if p2:\n",
    "    with open('file.txt', 'r') as file:\n",
    "        for i,line in enumerate(file):\n",
    "            generate_wav(line,i)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe2aea-eb9a-402a-9933-5d35158551af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
